\section{Basic Theory}
When dealing with systems with a lot of users and a lot of content it can be beneficial to try and help users find content that they would like.
This is usually done through recommender systems.
There are broadly speaking two approaches to recommender systems which are content-based filtering and collaborative filtering.
Content-based filtering is done by recommending items that are similar to items that the user had like before.
This approach uses features that have to be hand engineered by categorizing the items.
Collaborative filtering on the other hand uses both relationship between users and the inter dependencies among items to provide recommendations \cite{Matrix-factorization-techniques}. 
This means that collaborative filtering recommends an item to a user based on a similar user.

The advantage with collaborative filtering is that the features are learned automatically and it does not rely on hand engineered features which makes it more scalable for larger domains with many users and items.
These features are called latent features.
In general collaborative filtering is more accurate than content-based filtering \cite{Matrix-factorization-techniques}.
But collaborative filtering suffers from the cold start problem which means that it does not deal well with new users that have not rated any items yet.

\subsection{Matrix factorization}
The data concerning users and items can be represented as a matrix where each row represents a user and each column an item.
The entries in the matrix will then be the explicit feedback given for that item by the user if there is any.
This will be quite a sparse matrix in most cases.
Matrix factorization can then be used to infer user preference for the items not rated by the user by using implicit feedback which can be purchase history, browsing history, mouse movement or any behavioral patterns that the user has.
We can estimate if a user is going to like an item by analyzing the behavior of the users \cite{Matrix-factorization-techniques}.
We start out with a matrix $A = N x M$ where N is the number of users and M is the number of items.
The implicit feedback is used to learn the latent features of the items and the users liking of those latent features.
This is done by mapping users and items to a joint latent factor space of dimensionality $f$.
The items will then be associated with a vector $q_i \: \epsilon \: \mathbb{R}_f$ and the user will be associated with a vector $p_u \: \epsilon \: \mathbb{R}_f$. 
The matrix $q_i$ has the dimensions $k x m$ where k is the number of latent features and m is the number of items.
Matrix $q_u$ has the dimensions $n x k$ where n is the number of users and k is the number of latent features.
For each item i their corresponding entry in $q_i$ will measure the extent in which the item possesses the feature and for each user u their corresponding entry in $q_u$ will measure their liking to each feature.
By then calculating the dot product $q_i^T p_u$ the resulting matrix will capture an estimate of what each user would rate each item. 
The main challenge of using the matrix factorization model is finding a good algorithm for computing the mapping of each item to the factor vectors $q_i$ and $q_u$.
After the factor vectors are computed the task of estimating the rating a user will give an item is easy through the following equation $r_{ui} \: = \: q_i^T p_u$ where $r_{ui}$ is the resulting ratings matrix.

\subsection{Graph Convolutional Network}
Graph Convolutional Network (GCN) is a neural network architecture that operates on graphs.
Given a graph $G = (V,E)$ a GCN takes the input of a adjacency
matrix $A$ with size of $N x N$ that represents graph $G$ and a feature matrix $N x F^0$, where $N$ is the total amount of nodes and $F^0$ is the total amount of input features for each node.
A hidden layer in a GCN can be defined as $H^i = f(H^{i-1}, A)$ where $i$ indicates the layer and $H^0$ is the previously mentioned $N x F^0$ feature matrix and $f$ is a propagation function \cite{Deep-Learning-on-Graphs-with-GCN}.
There are many different types of propagation functions.
A simple example could be $f(H^i, A) = \sigma(AH^iW^i) = H^{i+1}$ where $W^i$ is the weight matrix at layer $i$ and $\sigma$ is a non-linear activation function \cite{Deep-Learning-on-Graphs-with-GCN}.
The intuition behind this propagation function is that the future representation of each node is calculated based on its neighbors nodes.
Because of this, each time $i$ is increased, a node's new value is therefore affected not only by its neighbors but its neighbors' neighbors and so on.
An issue with this propagation function could be that the value of each node now is a sum of each of its neighbors, and therefore loses its own value.
This could be solved by replacing $A$ with $\hat{A} = A + I$ where $I$ is the identity matrix.
Doing this the node considers itself a neighbor.
