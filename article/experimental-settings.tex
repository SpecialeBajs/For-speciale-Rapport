\subsection{Experimental Settings}
Throughout this subsection the experimental settings and evaluation metrics such as Recall and NDCG are described.

\subsubsection{Parameter settings}
All baseline methods use BPR loss as their loss function and have the embedding size set to 64.
For optimization Adam is used with an initial learning rate of $1e-4$.
BPR is described in Appendix \ref{subsubsec:BPR} and Adam is described in Appendix \ref{subsubsec:Adam}.
The batch size is set to 2048.
For all test in \autoref{subsec:performance-com}, the number of convolutions are set to 3.
The settings for PUP are different as the authors of PUP used other settings.
The batch size for PUP is 1024, and the initial learning rate is $1e-2$.
PUP never specifies in their paper, how many convolutions they used in their experiments, but with the code we received, we came to the conclusion that they only use 1 convolution in PUP.

\subsubsection{Evaluation metrics}
The evaluation metrics used for rating top k recommendation are Recall@K and NDCG@K where K is set to 50 and 100.
Throughout this subsection we describe Parameter settings, NDCG, Recall and Precision.

\subsubsection{NDCG}
Normalized Discounted Cumulative Gain (NDCG) is a measure of ranking quality \cite{NDCG-evaluation}.
To calculate the value of NDCG, it is necessary to first calculate the Discounted Cumulative Gain (DCG).
The equation for DCG is,
\begin{equation}
    DCG = \sum_{i=1}^{n} \frac{relevance_i}{log_2(i+1)},
\end{equation}
where $relevance_i$ is the predicted relevance for item $i$ and where $n$ is the total number of items.
DCG takes the placement into account, so that the array with the most relevant items first in the array will have the largest value \cite{NDCG-evaluation,Handbook}.
An example could be two arrays with the same values. such as $A = [1, 2, 3, 1]$, and $B = [3, 2, 1, 1]$. The results are $DCG(A) = 4.1925$ and $DCG(B) = 5.1925$, where it can be seen that the array with the most relevant items first has the highest value.
NDCG normalizes DCG, so that the recommendations can be compared, as the rating can vary from user to user.
NDCG is calculated as follows,
\begin{equation}
    NDCG = \frac{DCG}{iDCG},
\end{equation}
where $iDCG$ is the DCG with the ideal order \cite{NDCG-evaluation,Handbook}.

\subsubsection{Recall and Precision}
Recall and precision are calculated from the possible outcomes of the recommended items, which can be seen in \autoref{tab:possible-results}.
\begin{table}[]
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        \rowcolor[HTML]{FFFFFF}
                 & Recommended               & \begin{tabular}[c]{@{}l@{}}Not \\ recommended\end{tabular} \\ \hline
        Used     & \begin{tabular}[c]{@{}l@{}}True-Positive \\ (TP)\end{tabular} & \begin{tabular}[c]{@{}l@{}}False-Negative \\ (FN)\end{tabular} \\ \hline
        Not used & \begin{tabular}[c]{@{}l@{}}False-Positive\\ (FP)\end{tabular} & \begin{tabular}[c]{@{}l@{}}True-negative \\ (TN)\end{tabular} \\ \hline
    \end{tabular}
    \caption{Possible outcomes of a recommendation of an item to a user.}
    \label{tab:possible-results}
\end{table}
Precision describes how precise and accurate the model is from the recommended items, taking $TP$ and $FP$ into account.
Recall describes how accurate the model is related to the items that should be recommended, taking $TP$ and $FN$ into account.
Precision and recall are calculated as follows,
\begin{equation}
    Precision = \frac{\#TP}{\#TP + \# FP}
\end{equation}
\begin{equation}
    Recall = \frac{\#TP}{\#TP + \# FN},
\end{equation}
where \# indicates the total number of $TP$, $FP$, and $FN$.

\subsubsection{Baselines}
The results of the following methods are compared in our experiments.
\begin{itemize}
    \item \textbf{PUP} \cite{Priceaware}: PUP utilizes price and categories to improve the recommendation performance with Graph Convolutional Networks. A more detailed description of PUP can be seen in \autoref{subsec:price-intro}.
    \item \textbf{NGCF} \cite{NGCF_2019}: NGCF utilizes an embedding propagation layer with a Graph Convolutional Network. It was created with the purpose of collaborative filtering. More details can be seen in \autoref{subsec:lightgcn-ngcf}.
    \item \textbf{LightGCN} \cite{lightgcn}: LightGCN was created from NGCF and showed improved performance in Recall and NDCG by removing feature transformations and nonlinear activation function. More details can be seen in \autoref{subsec:lightgcn-ngcf}.
    \item \textbf{GCN} \cite{kipf2017semisupervised}: GCN is a method used for semi-supervised classification on graphs.
    \item \textbf{GC-MC} \cite{berg2017graph}: GC-MC utilizes Graph Convolutional Networks to create the representations for users and items. It only takes the first-order neighbor into account, and therefore only uses one convolution layer.
\end{itemize}
